
---
output: 
  html_document:
  pdf_document: default
  word_document: default
title: "Assignment 10: Predictive Modeling - Part 1"
---

***How to do it?***: 

- Open the Rmarkdown file of this assignment ([link](assignment10.Rmd)) in Rstudio. 

- Right under each **question**, insert  a code chunk (you can use the hotkey `Ctrl + Alt + I` to add a code chunk) and code the solution for the question. 

- `Knit` the rmarkdown file (hotkey: `Ctrl + Alt + K`) to export an html.  

-  Publish the html file to your Githiub Page. 

***Submission***: Submit the link on Github of the assignment to Canvas

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
```


-------

1. Use the `Adult Census Income` dataset.  We will predict the income (whether or not it is more than 50k or not) of an adult. Import the dataset.  Partition the data into 80% training and 20% testing.  

```{r}
library(dplyr)
library(ggplot2)
library(gganimate)
library(tidyverse)
library(lubridate)

df <- read_csv("~/Statistical Analysis with R/adult_census.csv")

df <- df %>% 
  rename(target=income)

df <- df %>% 
  mutate(target = as.factor(target),
         workclass = as.factor(workclass),
         education = as.factor(education),
         marital.status = as.factor(marital.status),
         occupation = as.factor(occupation),
         relationship = as.factor(relationship),
         race = as.factor(race),
         sex = as.factor(sex),
         native.country = as.factor(native.country))

library(caret)
set.seed(2020)
splitIndex <- createDataPartition(df$target, p=.8, list = FALSE)

df_training <- df[splitIndex,]
df_testing <- df[-splitIndex,]
```

2. Practice Decision Tree.  Do the follows:

  - Use `rpart` package, create a decision tree with maximum depth of 3. 

```{r}
library(rpart)

tree_model <- rpart(target ~ .,data = df_training, control = rpart.control(maxdepth = 3))
```
  
  - Calculate the accuracy of the model on the testing data. Notice that the positive outcome here is not `1` but `>50K` or `<50K`. 

```{r}
pred <- predict(tree_model, df_testing, type = "class")

cm <- confusionMatrix(data = pred, reference = df_testing$target)

cm$overall[1]
```
  
  - Plot the tree

```{r}
library(rattle)

fancyRpartPlot(tree_model)
```
  
  - Plot the variable importance by the tree

```{r}
tree_model$variable.importance

barplot(tree_model$variable.importance)
```
  
3. Create 3 more trees and compare the testing accuracy of these trees, which tree give the highest testing accuracy.

```{r}
#Tree 1
tree_model1 <- rpart(target ~ .,data = df_training, control = rpart.control(maxdepth = 1))

pred1 <- predict(tree_model1, df_testing, type = "class")

cm1 <- confusionMatrix(data = pred1, reference = df_testing$target)

cm1$overall[1]
#0.7592138  

#Tree 2
tree_model2 <- rpart(target ~ .,data = df_training, control = rpart.control(maxdepth = 2))

pred2 <- predict(tree_model2, df_testing, type = "class")

cm2 <- confusionMatrix(data = pred2, reference = df_testing$target)

cm2$overall[1]
#0.8264742 

#Tree 3
tree_model3 <- rpart(target ~ .,data = df_training, control = rpart.control(maxdepth = 9))

pred3 <- predict(tree_model3, df_testing, type = "class")

cm3 <- confusionMatrix(data = pred3, reference = df_testing$target)

cm3$overall[1]
#0.8387592 
```

4. Practice Random Forest.  Do the follows: 

  - Use `randomForest` package, create a random forest of 1000 trees. 
  
  - Calculate the accuracy of the model on the testing data. 

```{r}
library(randomForest)

forest_model = randomForest(target ~ ., data = df_training, ntree = 1000)
pred <- predict(forest_model, df_testing, type = "class")

cm <- confusionMatrix(data = pred, reference = df_testing$target)

cm$overall[1]
```

  - Plot the variable importance by the forest

```{r}
importance(forest_model)
```

5. Create 3 more forests and compare the testing accuracy of these forests, which forest give the highest testing accuracy.

```{r}
#forest 1
forest_model = randomForest(target ~ ., data = df_training, ntree = 500)
pred <- predict(forest_model, df_testing, type = "class")

cm <- confusionMatrix(data = pred, reference = df_testing$target)

cm$overall[1]
#0.8594902 

#forest 2
forest_model = randomForest(target ~ ., data = df_training, ntree = 750)
pred <- predict(forest_model, df_testing, type = "class")

cm <- confusionMatrix(data = pred, reference = df_testing$target)

cm$overall[1]
#0.8588759 

#forest 3
forest_model = randomForest(target ~ ., data = df_training, ntree = 2000)
pred <- predict(forest_model, df_testing, type = "class")

cm <- confusionMatrix(data = pred, reference = df_testing$target)

cm$overall[1]
#0.8607187
```

6. What is the best model (in term of testing accuracy) among all models (including trees and forests) you have trained?

```{r}
#The best model is the third forest model with a testing accuracy of .86
forest_model = randomForest(target ~ ., data = df_training, ntree = 2000)
pred <- predict(forest_model, df_testing, type = "class")

cm <- confusionMatrix(data = pred, reference = df_testing$target)

cm$overall[1]
```

